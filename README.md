# Language-Models
## Project Summary:
Using Python, I trained Unigram and N-gram language models using a large piece of text from  Project Gutenberg. I used tokenization, probability calculations, 
and sampling along to  train my models.

This project was completed in Jupyter Notebook along with the use of Pandas, and NumPy.
