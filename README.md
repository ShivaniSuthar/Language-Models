# Language-Models
## Project Summary:
Using Python, I trained Unigram and N-gram language models using a large piece of text from  Project Gutenberg. I used tokenization, probability calculations, 
and sampling along with Jupyter Notebook, Pandas, and NumPy to  train my models.
